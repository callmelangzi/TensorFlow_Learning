```python 
import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data
import matplotlib.pyplot as plt

mnist = input_data.read_data_sets(r"D:\迅雷下载\mnist", one_hot=True)
train_x = mnist.train.images
validation_x = mnist.validation.images
test_x = mnist.test.images
# 加载训练集标签
train_y = mnist.train.labels
# 加载验证集标签
validation_y = mnist.validation.labels
# 加载测试集标签
test_y =mnist.test.labels

'''
数据集
# 55000训练集
# 5000 验证集
# 10000 测试集

# print('train_x.shape:',train_x.shape,'train_y.shape:',train_y.shape)
# print('validation_x.shape',validation_x.shape,'validation_y.shape',validation_y.shape)
# print('test_x.shape',test_x.shape,'test_y.shape',test_y.shape)
'''


'''
# 展示具体图片
img = train_x[0].reshape(28,28)
plt.imshow(img,cmap='Greys')
plt.show()
'''

'''
CNN 数字识别
1.输入层
2.卷积层
3.激活层
4.池化层

5.全连接层
'''
with tf.name_scope("input"):
    x = tf.placeholder(tf.float32, [None, 784])
    y = tf.placeholder(tf.float32, [None, 10])
    '''
    对x维度进行转换 适用于卷积层计算
    '''
    x_image = tf.reshape(x,[-1,28,28,1])

with tf.name_scope('conv_layer1'):
    # 卷积层维度定义
    # 5 5 1 32 滑动窗口长， 宽， 输入通道数， 输出通道数
    w = tf.Variable(tf.truncated_normal([5, 5, 1, 32], stddev=0.1), name = 'w')
    b = tf.Variable(tf.constant(0.0, shape=[32]), name="b")
    # 卷积计算
    conv = tf.nn.bias_add(tf.nn.conv2d(x_image, w, strides=[1, 1, 1, 1], padding='SAME'), b, name="conv")
    active = tf.nn.relu(conv)
    # 池化 max_pooling
    pool = tf.nn.max_pool(active,ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

with tf.name_scope('conv_layer2'):
    # 第二层卷积层
    # 5 5 32 64
    w = tf.Variable(tf.truncated_normal([5, 5, 32, 64], stddev=0.1), name='w')
    b = tf.Variable(tf.constant(0.0, shape=[64]), name="b")
    # 卷积计算
    conv = tf.nn.bias_add(tf.nn.conv2d(pool, w, strides=[1, 1, 1, 1], padding='SAME'), b, name="conv")
    active = tf.nn.relu(conv)
    # 池化 max_pooling
    pool = tf.nn.max_pool(active, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')

with tf.name_scope('full_layer1'):

    # 28 * 28 的初始数据 经卷积计算后大小没有改变 池化后变为 14 * 14
    # 14 * 14 经过第二层池化后变为 7 * 7
    # 第二层卷积之后，我们图像的形状为  NHWC  =>  [N, 7, 7, 64]
    # 1024 ?
    w = tf.Variable(tf.truncated_normal([7 * 7 * 64, 1024], stddev=0.1),name='w')
    b = tf.Variable(tf.constant(0.0,shape=[1024]),name = 'b')
    pool = tf.reshape(pool,[-1, 7*7*64])
    active = tf.nn.relu(tf.matmul(pool,w) + b)
    # 执行dropout（随机丢弃）

    keep_prob = tf.placeholder(tf.float32)
    drop = tf.nn.dropout(active, keep_prob)

with tf.name_scope('full_layer2'):
    # 第二层全连接层
    w = tf.Variable(tf.truncated_normal([1024,10], stddev=0.1), name='w')
    b = tf.Variable(tf.constant(0.0, shape=[10]), name='b')
    logits = tf.matmul(drop, w) + b


with tf.name_scope('compute'):
    # 损失函数计算
    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits) )
    train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)

    # 计算准确率
    correct = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))
    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))


with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    train_acc = []
    test_acc = []

    for i in range(1,1001):
        batch = mnist.train.next_batch(64)

        if i % 100 == 0:
            train_accuracy = accuracy.eval(
                feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})
            test_accuracy = accuracy.eval(
                feed_dict={x: mnist.test.images[:5000], y: mnist.test.labels[:5000], keep_prob: 1.0})
            print(f"step {i}, training accuracy {train_accuracy * 100:.2f}%")
            print(f"step {i}, test accuracy {test_accuracy * 100:.2f}%")
        if i % 20 == 0:
            train_acc.append(accuracy.eval(
                    feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0}))
            test_acc.append(accuracy.eval(
                    feed_dict={x: mnist.test.images[:5000], y: mnist.test.labels[:5000], keep_prob: 1.0}))
        train_step.run(feed_dict = {x: batch[0], y: batch[1], keep_prob: 0.5} )

    plt.plot(train_acc,label ='train_acc')
    plt.plot(test_acc,label ='test_acc')
    plt.title('1000-epochs acc')
    plt.legend()

    plt.show()
```
